{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":73291,"databundleVersionId":8930475,"sourceType":"competition"},{"sourceId":186447738,"sourceType":"kernelVersion"},{"sourceId":186521966,"sourceType":"kernelVersion"},{"sourceId":186618913,"sourceType":"kernelVersion"},{"sourceId":186824337,"sourceType":"kernelVersion"},{"sourceId":187156793,"sourceType":"kernelVersion"}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# IMPORTS","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom sklearn.preprocessing import MinMaxScaler\nimport warnings\n\n# Ignore all warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-07-03T03:33:26.117693Z","iopub.execute_input":"2024-07-03T03:33:26.118003Z","iopub.status.idle":"2024-07-03T03:33:26.124506Z","shell.execute_reply.started":"2024-07-03T03:33:26.117982Z","shell.execute_reply":"2024-07-03T03:33:26.123473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets=[\"Response\"]\ntarget=targets[0]","metadata":{"execution":{"iopub.status.busy":"2024-07-03T03:33:26.126167Z","iopub.execute_input":"2024-07-03T03:33:26.126482Z","iopub.status.idle":"2024-07-03T03:33:26.135027Z","shell.execute_reply.started":"2024-07-03T03:33:26.126438Z","shell.execute_reply":"2024-07-03T03:33:26.134103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# GENERALIZATION CONCEPT","metadata":{}},{"cell_type":"markdown","source":"<font size=\"3\"> We can use different types of means such as Geometric Mean, Arithmetic Mean, and Harmonic Mean</font>\n\n * **Geometric Mean:**\nThe Geometric Mean is calculated by taking the nth root of the product of n numbers.\n\nGeometric Mean = (x₁ * x₂ * x₃ * ... * xₙ)^(1/n)\n\n* **Arithmetic Mean:**\nThe Arithmetic Mean is the sum of all the numbers in a series divided by the total number of values.\n\nArithmetic Mean = (x₁ + x₂ + x₃ + ... + xₙ) / n\n\n* **Harmonic Mean:**\nThe Harmonic Mean is calculated by taking the reciprocal of the arithmetic mean of the reciprocals of the numbers in the series.\n\nHarmonic Mean = n / ((1/x₁) + (1/x₂) + (1/x₃) + ... + (1/xₙ))\n\nwhere x₁ , x₂ , x₃ , ... ,xₙ are vectors predicted from each submission\n\n<font size=\"3\">For a set of positive predictions, the Harmonic Mean is the smallest, followed by the Geometric Mean, and then the Arithmetic Mean with the largest values on average</font>\n\n**When to use:**\n1. Geometric Mean is less sensitive to extreme values (outliers) in the data compared to the arithmetic mean. This can give a better results and reduces overfitted predictions.\n2. Arithmetic Mean is sensitive to extreme values. One very large or very small number can significantly affect the mean. Applicable for cases where large predictions are important. \n3. Harmonic Mean can give more weightage to smaller numbers among the predictions, risk averse method to establish a safe prediction.\n\n","metadata":{}},{"cell_type":"code","source":"def ensemble_mean(sub_list,cols, mean=\"AM\"):\n    \n    \"\"\"\n    The function computes Arithmetic Mean/Geometric Mean/Harmonic Mean given a list of results with specific results.\n    \"\"\"\n    \n    sub_out=sub_list[0].copy()\n    if mean==\"AM\":\n        for col in cols:\n            sub_out[col]=sum(df[col] for df in sub_list)/len(sub_list)\n    elif mean==\"GM\":\n        for df in sub_list[1:]:\n            for col in cols:\n                sub_out[col]*=df[col]\n        for col in cols:\n            sub_out[col]=(sub_out[col])**(1/len(sub_list))\n    elif mean==\"HM\":\n        for col in cols:\n            sub_out[col]=len(sub_list)/sum(1/df[col] for df in sub_list)\n    \n    return sub_out","metadata":{"execution":{"iopub.status.busy":"2024-07-03T03:33:26.136675Z","iopub.execute_input":"2024-07-03T03:33:26.13701Z","iopub.status.idle":"2024-07-03T03:33:26.147904Z","shell.execute_reply.started":"2024-07-03T03:33:26.136982Z","shell.execute_reply":"2024-07-03T03:33:26.146662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Selected Public Notebooks\n\nThanks to the authors for their good work\n\n1. by [@rohanrao](https://www.kaggle.com/code/rohanrao/automl-grand-prix-1st-place-solution)\n2. by [@thegodchurch](https://www.kaggle.com/code/thegodchurch/lightbgm-finetuned)\n3. by [@ravi20076](https://www.kaggle.com/code/ravi20076/playgrounds4e07-eda-baseline-v1)\n4. by [@rzatemizel](https://www.kaggle.com/code/rzatemizel/single-model-baseline-xgboost)\n5. by [@innixma](https://www.kaggle.com/code/innixma/4th-place-automl-grand-prix-automl-grandmasters)\n","metadata":{}},{"cell_type":"code","source":"sub_ext1=pd.read_csv(\"/kaggle/input/automl-grand-prix-1st-place-solution/submission.csv\")\nsub_ext2=pd.read_csv(\"/kaggle/input/lightbgm-finetuned/submission.csv\")\nsub_ext3=pd.read_csv(\"/kaggle/input/playgrounds4e07-eda-baseline-v1/submission_V1.csv\")\nsub_ext4=pd.read_parquet(\"/kaggle/input/single-model-baseline-xgboost/submission.parquet\")\nsub_ext5=pd.read_csv(\"/kaggle/input/4th-place-automl-grand-prix-automl-grandmasters/submission.csv\")\n\ndef scale(df,targets):\n    sc=MinMaxScaler()\n    df[targets]=sc.fit_transform(df[targets])\n    \n    return df\n\nsub_ext1=scale(sub_ext1,targets)\nsub_ext2=scale(sub_ext2,targets)\nsub_ext3=scale(sub_ext3,targets)\nsub_ext4=scale(sub_ext4,targets)\nsub_ext5=scale(sub_ext5,targets)","metadata":{"execution":{"iopub.status.busy":"2024-07-03T03:33:26.149035Z","iopub.execute_input":"2024-07-03T03:33:26.149266Z","iopub.status.idle":"2024-07-03T03:33:34.54178Z","shell.execute_reply.started":"2024-07-03T03:33:26.149245Z","shell.execute_reply":"2024-07-03T03:33:34.540889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Choose Weights\n\nThere are two ways to assign weights:\n1) Assign higher weights to high Public LB result, it's more trial and error just to increase the Public LB. It makes more sense to just give ranks based on Public LB scores.\n2) A better way is ranking them based on their CV score and assign a higher rank to higher CV result, it would be more generalized to use ordered numbers (n, n-1, n-2,…)","metadata":{}},{"cell_type":"code","source":"sub_list=[sub_ext1,sub_ext2, sub_ext3,sub_ext4,sub_ext5] # list all the results\n\nweights=np.square([4,4,3,2,1])\nif len(sub_list)==len(weights):\n    weighted_list = [item for sublist, weight in zip(sub_list, weights) for item in [sublist] * weight]\n\nsub_ensemble=ensemble_mean(weighted_list,targets,mean=\"AM\")\nsub_ensemble.to_csv('submission.csv',index=False)\nsub_ensemble.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-03T03:33:34.543835Z","iopub.execute_input":"2024-07-03T03:33:34.544194Z","iopub.status.idle":"2024-07-03T03:33:50.004941Z","shell.execute_reply.started":"2024-07-03T03:33:34.544165Z","shell.execute_reply":"2024-07-03T03:33:50.004018Z"},"trusted":true},"execution_count":null,"outputs":[]}]}