{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "957f07aa",
   "metadata": {
    "papermill": {
     "duration": 0.005346,
     "end_time": "2024-06-16T02:27:16.218165",
     "exception": false,
     "start_time": "2024-06-16T02:27:16.212819",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Initialization\n",
    "\n",
    "This notebook is forked and inspired from the [BELKA 1DCNN Starter](https://www.kaggle.com/code/ahmedelfazouan/belka-1dcnn-starter-with-all-data/notebook).\n",
    "\n",
    "This original notebook attempted to encoded the smiles of all the train & test set and saved it locally, this may take up to 1 hour on TPU for each fold. While the original notebook only utilize one fold, there are only 1/15 data used for training, due to the limit of computational power. Therefore, I pre-tained one model for each fold and store the model weights locally so that the prediction results could be combined to make better LB score. The models are stored [here](https://www.kaggle.com/datasets/hugowjd/1dcnn-models-for-belka-competition).\n",
    "\n",
    "The encoded data is stored [here](https://www.kaggle.com/datasets/ahmedelfazouan/belka-enc-dataset) , \n",
    "\n",
    "How to improve :\n",
    "* Change the fold size (better machine may deal with smaller fold number)\n",
    "* Try another model like Transformer, or LSTM.\n",
    "* Train for more epochs for each folds.\n",
    "* Add more features like a one hot encoding of bb2 or bb3.\n",
    "* And of ensembling with other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0420bd82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T02:27:16.227964Z",
     "iopub.status.busy": "2024-06-16T02:27:16.227714Z",
     "iopub.status.idle": "2024-06-16T02:27:17.455724Z",
     "shell.execute_reply": "2024-06-16T02:27:17.454969Z"
    },
    "papermill": {
     "duration": 1.235502,
     "end_time": "2024-06-16T02:27:17.457615",
     "exception": false,
     "start_time": "2024-06-16T02:27:16.222113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/belka-enc-dataset/train_enc.parquet\n",
      "/kaggle/input/belka-enc-dataset/test_enc.parquet\n",
      "/kaggle/input/leash-BELKA/sample_submission.csv\n",
      "/kaggle/input/leash-BELKA/train.parquet\n",
      "/kaggle/input/leash-BELKA/test.parquet\n",
      "/kaggle/input/leash-BELKA/train.csv\n",
      "/kaggle/input/leash-BELKA/test.csv\n",
      "/kaggle/input/1dcnn-models-for-belka-competition/model-1.h5\n",
      "/kaggle/input/1dcnn-models-for-belka-competition/model-12.h5\n",
      "/kaggle/input/1dcnn-models-for-belka-competition/model-9.h5\n",
      "/kaggle/input/1dcnn-models-for-belka-competition/model-2.h5\n",
      "/kaggle/input/1dcnn-models-for-belka-competition/model-13.h5\n",
      "/kaggle/input/1dcnn-models-for-belka-competition/model-4.h5\n",
      "/kaggle/input/1dcnn-models-for-belka-competition/model-7.h5\n",
      "/kaggle/input/1dcnn-models-for-belka-competition/model-0.h5\n",
      "/kaggle/input/1dcnn-models-for-belka-competition/model-14.h5\n",
      "/kaggle/input/1dcnn-models-for-belka-competition/model-11.h5\n",
      "/kaggle/input/1dcnn-models-for-belka-competition/model-8.h5\n",
      "/kaggle/input/1dcnn-models-for-belka-competition/model-10.h5\n",
      "/kaggle/input/1dcnn-models-for-belka-competition/model-3.h5\n",
      "/kaggle/input/1dcnn-models-for-belka-competition/model-5.h5\n",
      "/kaggle/input/1dcnn-models-for-belka-competition/model-6.h5\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec17751e",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-06-16T02:27:17.467735Z",
     "iopub.status.busy": "2024-06-16T02:27:17.467424Z",
     "iopub.status.idle": "2024-06-16T02:27:23.709713Z",
     "shell.execute_reply": "2024-06-16T02:27:23.708784Z"
    },
    "papermill": {
     "duration": 6.250128,
     "end_time": "2024-06-16T02:27:23.712020",
     "exception": false,
     "start_time": "2024-06-16T02:27:17.461892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fastparquet -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ebae893",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-16T02:27:23.724252Z",
     "iopub.status.busy": "2024-06-16T02:27:23.723919Z",
     "iopub.status.idle": "2024-06-16T02:27:25.388178Z",
     "shell.execute_reply": "2024-06-16T02:27:25.387365Z"
    },
    "papermill": {
     "duration": 1.673421,
     "end_time": "2024-06-16T02:27:25.390494",
     "exception": false,
     "start_time": "2024-06-16T02:27:23.717073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import average_precision_score as APS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a21f69a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T02:27:25.400667Z",
     "iopub.status.busy": "2024-06-16T02:27:25.400388Z",
     "iopub.status.idle": "2024-06-16T02:27:25.405162Z",
     "shell.execute_reply": "2024-06-16T02:27:25.404454Z"
    },
    "papermill": {
     "duration": 0.011693,
     "end_time": "2024-06-16T02:27:25.406798",
     "exception": false,
     "start_time": "2024-06-16T02:27:25.395105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "\n",
    "    PREPROCESS = False\n",
    "    EPOCHS = 15\n",
    "    BATCH_SIZE = 4096\n",
    "    LR = 1e-3\n",
    "    WD = 0.05\n",
    "    # Number of folds\n",
    "    NBR_FOLDS = 15\n",
    "    PRETRAINED = True\n",
    "    # Only the first fold selected\n",
    "    SELECTED_FOLDS = []\n",
    "    EXIST_MODELS = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "\n",
    "    SEED = 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27c27db9",
   "metadata": {
    "_kg_hide-output": true,
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-06-16T02:27:25.416528Z",
     "iopub.status.busy": "2024-06-16T02:27:25.416294Z",
     "iopub.status.idle": "2024-06-16T02:28:04.172675Z",
     "shell.execute_reply": "2024-06-16T02:28:04.171539Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 38.764524,
     "end_time": "2024-06-16T02:28:04.175324",
     "exception": false,
     "start_time": "2024-06-16T02:27:25.410800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D0616 02:27:56.809787914      14 config.cc:119]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\n",
      "D0616 02:27:56.809810275      14 config.cc:119]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\n",
      "D0616 02:27:56.809813747      14 config.cc:119]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\n",
      "D0616 02:27:56.809816248      14 config.cc:119]                        gRPC EXPERIMENT flow_control_fixes                  ON  (default:ON)\n",
      "D0616 02:27:56.809818498      14 config.cc:119]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\n",
      "D0616 02:27:56.809821000      14 config.cc:119]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\n",
      "D0616 02:27:56.809823426      14 config.cc:119]                        gRPC EXPERIMENT new_hpack_huffman_decoder           ON  (default:ON)\n",
      "D0616 02:27:56.809829895      14 config.cc:119]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\n",
      "D0616 02:27:56.809832423      14 config.cc:119]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\n",
      "D0616 02:27:56.809835088      14 config.cc:119]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\n",
      "D0616 02:27:56.809837245      14 config.cc:119]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\n",
      "D0616 02:27:56.809839434      14 config.cc:119]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\n",
      "D0616 02:27:56.809841658      14 config.cc:119]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\n",
      "D0616 02:27:56.809844030      14 config.cc:119]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\n",
      "I0616 02:27:56.810057470      14 ev_epoll1_linux.cc:122]               grpc epoll fd: 59\n",
      "D0616 02:27:56.810070921      14 ev_posix.cc:144]                      Using polling engine: epoll1\n",
      "D0616 02:27:56.810087967      14 dns_resolver_ares.cc:822]             Using ares dns resolver\n",
      "D0616 02:27:56.810595792      14 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\n",
      "D0616 02:27:56.810609160      14 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\n",
      "D0616 02:27:56.810612554      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\n",
      "D0616 02:27:56.810615353      14 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\n",
      "D0616 02:27:56.810618515      14 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\n",
      "D0616 02:27:56.810621245      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin_experimental\"\n",
      "D0616 02:27:56.810628535      14 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\n",
      "D0616 02:27:56.810647630      14 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\n",
      "D0616 02:27:56.810680646      14 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\n",
      "D0616 02:27:56.810699067      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\n",
      "D0616 02:27:56.810702706      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\n",
      "D0616 02:27:56.810705705      14 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\n",
      "D0616 02:27:56.810709269      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\n",
      "D0616 02:27:56.810712434      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\n",
      "D0616 02:27:56.810715411      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\n",
      "D0616 02:27:56.810719575      14 certificate_provider_registry.cc:35]  registering certificate provider factory for \"file_watcher\"\n",
      "I0616 02:27:56.815259936      14 socket_utils_common_posix.cc:408]     Disabling AF_INET6 sockets because ::1 is not available.\n",
      "I0616 02:27:56.849577603      14 socket_utils_common_posix.cc:337]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\n",
      "E0616 02:27:56.855633636      14 oauth2_credentials.cc:236]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2024-06-16T02:27:56.855615265+00:00\", grpc_status:2}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def set_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "set_seeds(seed=CFG.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac70237",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-06-16T02:28:04.186968Z",
     "iopub.status.busy": "2024-06-16T02:28:04.186370Z",
     "iopub.status.idle": "2024-06-16T02:28:13.010876Z",
     "shell.execute_reply": "2024-06-16T02:28:13.009086Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 8.832322,
     "end_time": "2024-06-16T02:28:13.012668",
     "exception": false,
     "start_time": "2024-06-16T02:28:04.180346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
      "INFO:tensorflow:Initializing the TPU system: local\n",
      "INFO:tensorflow:Finished initializing TPU system.\n",
      "INFO:tensorflow:Found TPU system:\n",
      "INFO:tensorflow:*** Num TPU Cores: 8\n",
      "INFO:tensorflow:*** Num TPU Workers: 1\n",
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n",
      "Running on TPU\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect(tpu=\"local\") # \"local\" for 1VM TPU\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    print(\"Running on TPU\")\n",
    "    print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "except tf.errors.NotFoundError:\n",
    "    print(\"Not on TPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38f1bb2",
   "metadata": {
    "papermill": {
     "duration": 0.00525,
     "end_time": "2024-06-16T02:28:13.023296",
     "exception": false,
     "start_time": "2024-06-16T02:28:13.018046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe5bc2f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T02:28:13.035061Z",
     "iopub.status.busy": "2024-06-16T02:28:13.034811Z",
     "iopub.status.idle": "2024-06-16T02:30:00.432677Z",
     "shell.execute_reply": "2024-06-16T02:30:00.431395Z"
    },
    "papermill": {
     "duration": 107.406676,
     "end_time": "2024-06-16T02:30:00.435058",
     "exception": false,
     "start_time": "2024-06-16T02:28:13.028382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if CFG.PREPROCESS:\n",
    "    enc = {'l': 1, 'y': 2, '@': 3, '3': 4, 'H': 5, 'S': 6, 'F': 7, 'C': 8, 'r': 9, 's': 10, '/': 11, 'c': 12, 'o': 13,\n",
    "           '+': 14, 'I': 15, '5': 16, '(': 17, '2': 18, ')': 19, '9': 20, 'i': 21, '#': 22, '6': 23, '8': 24, '4': 25, '=': 26,\n",
    "           '1': 27, 'O': 28, '[': 29, 'D': 30, 'B': 31, ']': 32, 'N': 33, '7': 34, 'n': 35, '-': 36}\n",
    "    train_raw = pd.read_parquet('/kaggle/input/leash-BELKA/train.parquet')\n",
    "    smiles = train_raw[train_raw['protein_name']=='BRD4']['molecule_smiles'].values\n",
    "    assert (smiles!=train_raw[train_raw['protein_name']=='HSA']['molecule_smiles'].values).sum() == 0\n",
    "    assert (smiles!=train_raw[train_raw['protein_name']=='sEH']['molecule_smiles'].values).sum() == 0\n",
    "    def encode_smile(smile):\n",
    "        tmp = [enc[i] for i in smile]\n",
    "        tmp = tmp + [0]*(142-len(tmp))\n",
    "        return np.array(tmp).astype(np.uint8)\n",
    "\n",
    "    smiles_enc = joblib.Parallel(n_jobs=96)(joblib.delayed(encode_smile)(smile) for smile in tqdm(smiles))\n",
    "    smiles_enc = np.stack(smiles_enc)\n",
    "    train = pd.DataFrame(smiles_enc, columns = [f'enc{i}' for i in range(142)])\n",
    "    train['bind1'] = train_raw[train_raw['protein_name']=='BRD4']['binds'].values\n",
    "    train['bind2'] = train_raw[train_raw['protein_name']=='HSA']['binds'].values\n",
    "    train['bind3'] = train_raw[train_raw['protein_name']=='sEH']['binds'].values\n",
    "    train.to_parquet('train_enc.parquet')\n",
    "\n",
    "    test_raw = pd.read_parquet('/kaggle/input/leash-BELKA/test.parquet')\n",
    "    smiles = test_raw['molecule_smiles'].values\n",
    "\n",
    "    smiles_enc = joblib.Parallel(n_jobs=96)(joblib.delayed(encode_smile)(smile) for smile in tqdm(smiles))\n",
    "    smiles_enc = np.stack(smiles_enc)\n",
    "    test = pd.DataFrame(smiles_enc, columns = [f'enc{i}' for i in range(142)])\n",
    "    test.to_parquet('test_enc.parquet')\n",
    "\n",
    "else:\n",
    "    train = pd.read_parquet('/kaggle/input/belka-enc-dataset/train_enc.parquet')\n",
    "    test = pd.read_parquet('/kaggle/input/belka-enc-dataset/test_enc.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa6bc66e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T02:30:00.447969Z",
     "iopub.status.busy": "2024-06-16T02:30:00.447404Z",
     "iopub.status.idle": "2024-06-16T02:30:00.469707Z",
     "shell.execute_reply": "2024-06-16T02:30:00.468825Z"
    },
    "papermill": {
     "duration": 0.030554,
     "end_time": "2024-06-16T02:30:00.471488",
     "exception": false,
     "start_time": "2024-06-16T02:30:00.440934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train set: (98415610, 145)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc0</th>\n",
       "      <th>enc1</th>\n",
       "      <th>enc2</th>\n",
       "      <th>enc3</th>\n",
       "      <th>enc4</th>\n",
       "      <th>enc5</th>\n",
       "      <th>enc6</th>\n",
       "      <th>enc7</th>\n",
       "      <th>enc8</th>\n",
       "      <th>enc9</th>\n",
       "      <th>...</th>\n",
       "      <th>enc135</th>\n",
       "      <th>enc136</th>\n",
       "      <th>enc137</th>\n",
       "      <th>enc138</th>\n",
       "      <th>enc139</th>\n",
       "      <th>enc140</th>\n",
       "      <th>enc141</th>\n",
       "      <th>bind1</th>\n",
       "      <th>bind2</th>\n",
       "      <th>bind3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   enc0  enc1  enc2  enc3  enc4  enc5  enc6  enc7  enc8  enc9  ...  enc135  \\\n",
       "0     8    22     8     8    28    12    27    12    12    12  ...       0   \n",
       "1     8    22     8     8    28    12    27    12    12    12  ...       0   \n",
       "2     8    22     8     8    28    12    27    12    12    12  ...       0   \n",
       "\n",
       "   enc136  enc137  enc138  enc139  enc140  enc141  bind1  bind2  bind3  \n",
       "0       0       0       0       0       0       0      0      0      0  \n",
       "1       0       0       0       0       0       0      0      0      0  \n",
       "2       0       0       0       0       0       0      0      0      0  \n",
       "\n",
       "[3 rows x 145 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of Train set:\", train.shape)\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a9e80dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T02:30:00.483843Z",
     "iopub.status.busy": "2024-06-16T02:30:00.483593Z",
     "iopub.status.idle": "2024-06-16T02:30:00.497217Z",
     "shell.execute_reply": "2024-06-16T02:30:00.496355Z"
    },
    "papermill": {
     "duration": 0.022362,
     "end_time": "2024-06-16T02:30:00.499107",
     "exception": false,
     "start_time": "2024-06-16T02:30:00.476745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Test set: (1674896, 142)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enc0</th>\n",
       "      <th>enc1</th>\n",
       "      <th>enc2</th>\n",
       "      <th>enc3</th>\n",
       "      <th>enc4</th>\n",
       "      <th>enc5</th>\n",
       "      <th>enc6</th>\n",
       "      <th>enc7</th>\n",
       "      <th>enc8</th>\n",
       "      <th>enc9</th>\n",
       "      <th>...</th>\n",
       "      <th>enc132</th>\n",
       "      <th>enc133</th>\n",
       "      <th>enc134</th>\n",
       "      <th>enc135</th>\n",
       "      <th>enc136</th>\n",
       "      <th>enc137</th>\n",
       "      <th>enc138</th>\n",
       "      <th>enc139</th>\n",
       "      <th>enc140</th>\n",
       "      <th>enc141</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 142 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   enc0  enc1  enc2  enc3  enc4  enc5  enc6  enc7  enc8  enc9  ...  enc132  \\\n",
       "0     8    22     8     8     8     8    29     8     3     5  ...       0   \n",
       "1     8    22     8     8     8     8    29     8     3     5  ...       0   \n",
       "2     8    22     8     8     8     8    29     8     3     5  ...       0   \n",
       "\n",
       "   enc133  enc134  enc135  enc136  enc137  enc138  enc139  enc140  enc141  \n",
       "0       0       0       0       0       0       0       0       0       0  \n",
       "1       0       0       0       0       0       0       0       0       0  \n",
       "2       0       0       0       0       0       0       0       0       0  \n",
       "\n",
       "[3 rows x 142 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of Test set:\", test.shape)\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be54ff0",
   "metadata": {
    "papermill": {
     "duration": 0.005715,
     "end_time": "2024-06-16T02:30:00.510328",
     "exception": false,
     "start_time": "2024-06-16T02:30:00.504613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "781c921f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T02:30:00.523530Z",
     "iopub.status.busy": "2024-06-16T02:30:00.523274Z",
     "iopub.status.idle": "2024-06-16T02:30:00.532981Z",
     "shell.execute_reply": "2024-06-16T02:30:00.532182Z"
    },
    "papermill": {
     "duration": 0.018974,
     "end_time": "2024-06-16T02:30:00.534740",
     "exception": false,
     "start_time": "2024-06-16T02:30:00.515766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1D-CNN model\n",
    "def OneDCNN_model():\n",
    "    with strategy.scope():\n",
    "        INP_LEN = 142\n",
    "        NUM_FILTERS = 32\n",
    "        hidden_dim = 128\n",
    "\n",
    "        inputs = tf.keras.layers.Input(shape=(INP_LEN,), dtype='int32')\n",
    "        x = tf.keras.layers.Embedding(input_dim=36, output_dim=hidden_dim, input_length=INP_LEN, mask_zero = True)(inputs)\n",
    "        x = tf.keras.layers.Conv1D(filters=NUM_FILTERS, kernel_size=3,  activation='relu', padding='valid',  strides=1)(x)\n",
    "        x = tf.keras.layers.Conv1D(filters=NUM_FILTERS*2, kernel_size=3,  activation='relu', padding='valid',  strides=1)(x)\n",
    "        x = tf.keras.layers.Conv1D(filters=NUM_FILTERS*3, kernel_size=3,  activation='relu', padding='valid',  strides=1)(x)\n",
    "        x = tf.keras.layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "        x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(0.1)(x)\n",
    "        x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(0.1)(x)\n",
    "        x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "        x = tf.keras.layers.Dropout(0.1)(x)\n",
    "\n",
    "        outputs = tf.keras.layers.Dense(3, activation='sigmoid')(x)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs = inputs, outputs = outputs)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=CFG.LR, weight_decay = CFG.WD)\n",
    "        loss = 'binary_crossentropy'\n",
    "        weighted_metrics = [tf.keras.metrics.AUC(curve='PR', name = 'avg_precision')]\n",
    "        model.compile(\n",
    "        loss=loss,\n",
    "        optimizer=optimizer,\n",
    "        weighted_metrics=weighted_metrics,\n",
    "        )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbeeb72",
   "metadata": {
    "papermill": {
     "duration": 0.005302,
     "end_time": "2024-06-16T02:30:00.545733",
     "exception": false,
     "start_time": "2024-06-16T02:30:00.540431",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train & Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3633360b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T02:30:00.558664Z",
     "iopub.status.busy": "2024-06-16T02:30:00.558379Z",
     "iopub.status.idle": "2024-06-16T02:32:39.188098Z",
     "shell.execute_reply": "2024-06-16T02:32:39.186960Z"
    },
    "papermill": {
     "duration": 158.638923,
     "end_time": "2024-06-16T02:32:39.190356",
     "exception": false,
     "start_time": "2024-06-16T02:30:00.551433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34 µs, sys: 10 µs, total: 44 µs\n",
      "Wall time: 87.5 µs\n",
      "Working on fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 02:30:35.336229: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-06-16 02:30:35.402645: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 6s 17ms/step\n",
      "Working on fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 02:30:43.865113: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-06-16 02:30:43.938686: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 6s 17ms/step\n",
      "Working on fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 02:30:52.292893: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-06-16 02:30:52.359311: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 6s 18ms/step\n",
      "Working on fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 02:31:00.710435: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-06-16 02:31:00.775808: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 6s 17ms/step\n",
      "Working on fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 02:31:09.056279: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-06-16 02:31:09.121495: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 6s 17ms/step\n",
      "Working on fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 02:31:18.310542: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-06-16 02:31:18.385823: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 7s 17ms/step\n",
      "Working on fold 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 02:31:26.756724: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-06-16 02:31:26.824635: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 6s 17ms/step\n",
      "Working on fold 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 02:31:35.188618: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-06-16 02:31:35.254183: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 6s 16ms/step\n",
      "Working on fold 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 02:31:43.285912: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-06-16 02:31:43.357568: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 6s 17ms/step\n",
      "Working on fold 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 02:31:51.622709: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-06-16 02:31:51.687255: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 6s 17ms/step\n",
      "Working on fold 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 02:31:59.811012: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-06-16 02:31:59.877650: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 6s 17ms/step\n",
      "Working on fold 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 02:32:08.069606: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-06-16 02:32:08.134642: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 6s 17ms/step\n",
      "Working on fold 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 02:32:16.987842: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-06-16 02:32:17.060783: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 7s 17ms/step\n",
      "Working on fold 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 02:32:25.275178: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-06-16 02:32:25.349009: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 6s 18ms/step\n",
      "Working on fold 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-16 02:32:33.780166: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n",
      "2024-06-16 02:32:33.846906: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 [==============================] - 6s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "FEATURES = [f'enc{i}' for i in range(142)] # The first 142 encoded columns as features\n",
    "TARGETS = ['bind1', 'bind2', 'bind3'] # Three types of binds as targets\n",
    "# 15 fold -> only train 1/15 of the entire dataset\n",
    "# If we got better machine, we may change NBR_FOLDS smaller\n",
    "skf = StratifiedKFold(n_splits = CFG.NBR_FOLDS, shuffle = True, random_state = 42) \n",
    "                                                                                    \n",
    "\n",
    "all_preds = []\n",
    "if CFG.PRETRAINED:\n",
    "    for fold,(train_idx, valid_idx) in enumerate(skf.split(train, train[TARGETS].sum(1))):\n",
    "        print(f\"Working on fold {fold}\")\n",
    "#         X_val = train.loc[valid_idx, FEATURES]\n",
    "#         y_val = train.loc[valid_idx, TARGETS]\n",
    "\n",
    "        model = OneDCNN_model()\n",
    "        model.load_weights(f\"/kaggle/input/1dcnn-models-for-belka-competition/model-{fold}.h5\")\n",
    "#         oof = model.predict(X_val, batch_size = 2*CFG.BATCH_SIZE)\n",
    "#         print('fold :', fold, 'CV score =', APS(y_val, oof, average = 'micro'))\n",
    "        preds = model.predict(test, batch_size = 2*CFG.BATCH_SIZE)\n",
    "        all_preds.append(preds)\n",
    "else:\n",
    "\n",
    "    for fold,(train_idx, valid_idx) in enumerate(skf.split(train, train[TARGETS].sum(1))):\n",
    "\n",
    "        if fold in CFG.EXIST_MODELS:\n",
    "            print(f\"Working on fold {fold}\")\n",
    "#             X_val = train.loc[valid_idx, FEATURES]\n",
    "#             y_val = train.loc[valid_idx, TARGETS]\n",
    "\n",
    "            model = OneDCNN_model()\n",
    "            model.load_weights(f\"/kaggle/input/1dcnn-models-for-belka-competition/model-{fold}.h5\")\n",
    "#             oof = model.predict(X_val, batch_size = 2*CFG.BATCH_SIZE)\n",
    "#             print('fold :', fold, 'CV score =', APS(y_val, oof, average = 'micro'))\n",
    "            preds = model.predict(test, batch_size = 2*CFG.BATCH_SIZE)\n",
    "            all_preds.append(preds)\n",
    "            continue;\n",
    "\n",
    "        if fold in CFG.SELECTED_FOLDS:\n",
    "            print(f\"Working on fold {fold}\")\n",
    "            X_train = train.loc[train_idx, FEATURES]\n",
    "            y_train = train.loc[train_idx, TARGETS]\n",
    "            X_val = train.loc[valid_idx, FEATURES]\n",
    "            y_val = train.loc[valid_idx, TARGETS]\n",
    "\n",
    "            es = tf.keras.callbacks.EarlyStopping(patience=5, monitor=\"val_loss\", mode='min', verbose=1)\n",
    "            checkpoint = tf.keras.callbacks.ModelCheckpoint(monitor='val_loss', filepath=f\"model-{fold}.h5\",\n",
    "                                                                save_best_only=True, save_weights_only=True,\n",
    "                                                            mode='min')\n",
    "            reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=5, verbose=1)\n",
    "            model = OneDCNN_model()\n",
    "            history = model.fit(\n",
    "                    X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=CFG.EPOCHS,\n",
    "                    callbacks=[checkpoint, reduce_lr_loss, es],\n",
    "                    batch_size=CFG.BATCH_SIZE,\n",
    "                    verbose=1,\n",
    "                )\n",
    "            model.load_weights(f\"model-{fold}.h5\")\n",
    "            oof = model.predict(X_val, batch_size = 2*CFG.BATCH_SIZE)\n",
    "            print('fold :', fold, 'CV score =', APS(y_val, oof, average = 'micro'))\n",
    "\n",
    "            preds = model.predict(test, batch_size = 2*CFG.BATCH_SIZE)\n",
    "            all_preds.append(preds)\n",
    "\n",
    "preds = np.mean(all_preds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10f76206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T02:32:39.260728Z",
     "iopub.status.busy": "2024-06-16T02:32:39.260385Z",
     "iopub.status.idle": "2024-06-16T02:32:39.265398Z",
     "shell.execute_reply": "2024-06-16T02:32:39.264591Z"
    },
    "papermill": {
     "duration": 0.041939,
     "end_time": "2024-06-16T02:32:39.267159",
     "exception": false,
     "start_time": "2024-06-16T02:32:39.225220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Predictions: 1674896 * 3\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Predictions: {len(preds)} * {len(preds[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0518690b",
   "metadata": {
    "papermill": {
     "duration": 0.033625,
     "end_time": "2024-06-16T02:32:39.336449",
     "exception": false,
     "start_time": "2024-06-16T02:32:39.302824",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52fd15ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T02:32:39.405807Z",
     "iopub.status.busy": "2024-06-16T02:32:39.404953Z",
     "iopub.status.idle": "2024-06-16T02:32:40.923045Z",
     "shell.execute_reply": "2024-06-16T02:32:40.921809Z"
    },
    "papermill": {
     "duration": 1.555591,
     "end_time": "2024-06-16T02:32:40.925286",
     "exception": false,
     "start_time": "2024-06-16T02:32:39.369695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained -> no plot\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Assuming 'history' is the object returned from model.fit()\n",
    "if CFG.PRETRAINED:\n",
    "    print(\"Pretrained -> no plot\")\n",
    "else:\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history.get('val_loss', [])  # Use get to avoid errors if validation loss is not available\n",
    "\n",
    "    train_prec = history.history['avg_precision']\n",
    "    val_prec = history.history.get('val_avg_precision', [])  # Similarly for validation accuracy\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_loss, label='Train')\n",
    "    if val_loss:\n",
    "        plt.plot(val_loss, label='Validation')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_prec, label='Train')\n",
    "    if val_prec:\n",
    "        plt.plot(val_prec, label='Validation')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a722f52a",
   "metadata": {
    "papermill": {
     "duration": 0.034368,
     "end_time": "2024-06-16T02:32:40.995186",
     "exception": false,
     "start_time": "2024-06-16T02:32:40.960818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "729e1fbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T02:32:41.066649Z",
     "iopub.status.busy": "2024-06-16T02:32:41.066281Z",
     "iopub.status.idle": "2024-06-16T02:32:47.829563Z",
     "shell.execute_reply": "2024-06-16T02:32:47.828509Z"
    },
    "papermill": {
     "duration": 6.801691,
     "end_time": "2024-06-16T02:32:47.831938",
     "exception": false,
     "start_time": "2024-06-16T02:32:41.030247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tst = pd.read_parquet('/kaggle/input/leash-BELKA/test.parquet')\n",
    "tst['binds'] = 0\n",
    "tst.loc[tst['protein_name']=='BRD4', 'binds'] = preds[(tst['protein_name']=='BRD4').values, 0]\n",
    "tst.loc[tst['protein_name']=='HSA', 'binds'] = preds[(tst['protein_name']=='HSA').values, 1]\n",
    "tst.loc[tst['protein_name']=='sEH', 'binds'] = preds[(tst['protein_name']=='sEH').values, 2]\n",
    "tst[['id', 'binds']].to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044543ab",
   "metadata": {
    "papermill": {
     "duration": 0.035864,
     "end_time": "2024-06-16T02:32:47.903108",
     "exception": false,
     "start_time": "2024-06-16T02:32:47.867244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 8006601,
     "sourceId": 67356,
     "sourceType": "competition"
    },
    {
     "datasetId": 4914065,
     "sourceId": 8275617,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5214038,
     "sourceId": 8700338,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30514,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 338.346454,
   "end_time": "2024-06-16T02:32:52.433203",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-16T02:27:14.086749",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
